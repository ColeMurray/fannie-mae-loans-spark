{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 405.023449\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from time import time\n",
    "\n",
    "df = spark.read.csv(path='./train.csv', inferSchema=True, header=True)\n",
    "df = df.withColumn('foreclosure_status', df['foreclosure_status'].cast('double'))\n",
    "\n",
    "## Let's stratify the data since we have a small amount of Foreclosures\n",
    "positive_count = df.filter(df['foreclosure_status'] == 1.0).count()\n",
    "data_size = df.count()\n",
    "strat_data = df.sampleBy('foreclosure_status', fractions={0: float(positive_count)/ data_size, 1: 1.0})\n",
    "print strat_data.groupby('foreclosure_status').count().toPandas()\n",
    "\n",
    "splitSeed = 12345\n",
    "train_data, test_data = strat_data.randomSplit([0.8, 0.2], splitSeed)\n",
    "\n",
    "\n",
    "feature_cols = df.drop('foreclosure_status').drop('id').columns\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
    "\n",
    "lr = LogisticRegression(labelCol='foreclosure_status', featuresCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.maxIter, [1, 10, 100]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "    .build()\n",
    "    \n",
    "\n",
    "    \n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=MulticlassClassificationEvaluator(labelCol='foreclosure_status', predictionCol='prediction'),\n",
    "                          numFolds=3)\n",
    "\n",
    "time_s = time()\n",
    "cv_model = crossval.fit(train_data)\n",
    "time_e = time()\n",
    "\n",
    "print 'Total training time: %f' % (time_e - time_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Accuracy: 0.765514\n",
      "Precision of True  0.757575757576\n",
      "Precision of False 0.772727272727\n",
      "Recall of True     0.714285714286\n",
      "Recall of False    0.809523809524\n",
      "F-1 Score          0.766233766234\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/2.0.1/libexec/python/pyspark/mllib/evaluation.py:262: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34.   8.]\n",
      " [ 10.  25.]]\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print 'Precision of True ', metrics.precision(1)\n",
    "    print 'Precision of False', metrics.precision(0)\n",
    "    print 'Recall of True    ', metrics.recall(1)\n",
    "    print 'Recall of False   ', metrics.recall(0)\n",
    "    print 'F-1 Score         ', metrics.fMeasure()\n",
    "    print 'Confusion Matrix\\n', metrics.confusionMatrix().toArray()\n",
    "    \n",
    "predictions = cv_model.transform(test_data)\n",
    "accuracy = cv_model.getEvaluator().evaluate(predictions)\n",
    "print 'F1 Accuracy: %f' % accuracy\n",
    "\n",
    "predictions_and_labels = predictions.select(\"prediction\", \"foreclosure_status\").rdd \\\n",
    ".map(lambda r: (float(r[0]), float(r[1])))\n",
    "\n",
    "print_metrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
